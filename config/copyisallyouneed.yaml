phrase_encoder_tokenizer: 
    zh: 123
    en: /apdcephfs/share_916081/ponybwcao/PLM/bert-base-cased
phrase_encoder_model: 
    zh: 123
    en: /apdcephfs/share_916081/ponybwcao/PLM/bert-base-cased
prefix_encoder_tokenizer: 
    zh: 123
    en: 
        small: /apdcephfs/share_916081/ponybwcao/PLM/GPT2-small
        medium: /apdcephfs/share_916081/ponybwcao/PLM/GPT2-medium
prefix_encoder_model: 
    zh: 123
    en: 
        small: /apdcephfs/share_916081/ponybwcao/PLM/GPT2-small
        medium: /apdcephfs/share_916081/ponybwcao/PLM/GPT2-medium

# pretrain configuration
pretrain:
    dropout: 0.1
    load_param: true
    lr: 0.00005
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 256
    warmup_ratio: 0.
    iter_to_accumulate: 1
    max_doc_size: 32
    buffer_size: 81920
    total_step: 400001
    save_every: 10000
    temp: 1.0
    doc_max_length: 512

# train configuration
train:
    dropout: 0.1
    load_param: true
    # lr: 5e-4 # 5e-5
    grad_clip: 1.0
    seed: 0
    max_len: 1024
    # max_doc_size: 32
    buffer_size: 10000
    # total_step: 100001
    # save_every: 10000
    # doc_max_length: 512

# Asynchronous training configuration
train_asyn:
    dropout: 0.1
    load_param: true
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 256
    max_doc_size: 32
    buffer_size: 81920
    total_step: 1000001
    save_every: 10000
    doc_max_length: 512

# pipeline training configuration
train_pipeline:
    dropout: 0.1
    load_param: true
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_query_len: 1024
    max_doc_size: 32
    buffer_size: 81920
    doc_max_length: 512

# query-side tuning configuration
queryside:
    dropout: 0.1
    load_param: true
    lr: 0.00005
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 256
    warmup_ratio: 0.
    iter_to_accumulate: 1
    max_query_num: 128
    candidate_phrase_num: 128 # GPU IVF max 2048
    buffer_size: 81920
    total_step: 200010
    save_every: 20000
    temp: 1.0
    doc_max_length: 512

# test configuration
test:
    seed: 0
    batch_size: 1
    prefix_length_rate: 0.5
    max_gen_len: 128
    dropout: 0.1
    doc_topk: 1024
    # phrase_topk for debug mode
    phrase_topk: 128
    left_window_size: 0
    right_window_size: 10

# train configuration
baseline:
    dropout: 0.1
    load_param: true
    lr: 0.00005
    grad_clip: 1.0
    seed: 0
    batch_size: 1
    max_len: 256
    warmup_ratio: 0.
    iter_to_accumulate: 1
    max_doc_size: 32
    buffer_size: 81920
    total_step: 1000010
    save_every: 50000
    temp: 1.0
    doc_max_length: 512
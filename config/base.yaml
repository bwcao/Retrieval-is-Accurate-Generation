datasets: 
    wikitext103: en
    wikipedia: en
    chinese_documents: zh
    lawmt: en
    en_wiki: en

models:
    copyisallyouneed: 
        model_name: 
            pretrain: CopyisallyouneedPretrain
            train: CopyisallyouneedPrefixOnly
            # train: CopyisallyouneedAllRefV2
            train_asyn: CopyisallyouneedAllRefV2Asyn
            train_pipeline: CopyisallyouneedAllRefV2Pipeline
            # train: CopyisallyouneedNegPrebatch
            test: CopyisallyouneedPrefixOnly
            # test: CopyisallyouneedAllRefV2Pipeline
            queryside: CopyisallyouneedQueryside
            baseline: Copyisallyouneed
        dataset_name: 
            wikitext103:
                pretrain: CopyisallyouneedWikitext103V2DatasetPretrain
                # train: CopyisallyouneedWikitext103V2DatasetPrebatchAllRef
                train: CopyisallyouneedWikitext103V2DatasetPrebatchAllRefAllCandidateV2
                train_asyn: CopyisallyouneedWikitext103V2DatasetPrebatchAllRefAllCandidateV2Asyn
                train_pipeline: CopyisallyouneedWikitext103V2DatasetPrebatchAllRefAllCandidateV2Asyn
                # train: CopyisallyouneedWikitext103V2DatasetNegPrebatch
                queryside: CopyisallyouneedWikitext103V2DatasetQueryside
                baseline: CopyisallyouneedWikitext103V2Dataset
                # train_neg: CopyisallyouneedWikitext103V2DatasetNeg
            wikipedia:
                train_pipeline: CopyisallyouneedWikipediaDataset
                train: CopyisallyouneedPrefixOnly
    gpt2:
        model_name: 
            train: GPT2Baseline
            test: GPT2Baseline
        # dataset_name: GPT2Dataset
        dataset_name: 
            wikitext103:
                train: GPT2Dataset
                test: GPT2Dataset
    knnlm:
        model_name: KNNLMBaseline
        # dataset_name: KNNLMInferenceDataset
        dataset_name: GPT2PPLDataset
